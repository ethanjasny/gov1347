---
title: 'Blog 3: Polling'
author: "Ethan Jasny"
date: '2022-09-26'
slug: []
categories: []
tags: []
---
```{r setup, include=FALSE}
# Hide all code output
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

# Import libraries
library(tidyverse)
library(ggplot2)
library(usmap)
library(sf)
library(blogdown)
library(plotly)
library(htmlwidgets)
library(gridExtra)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(kableExtra)


district_polls <- read_csv("538_house_polls_2022.csv")
hist_polls <- read_csv("polls_df.csv")
nat_polls <- read_csv("538_generic_poll_2022.csv")
PVI <- read.csv("PVIe.csv") %>%
  select(District, PVI)
GDP <- read_csv("GDP_quarterly.csv")
election_data <- read_csv("house_popvote_seats.csv")
```
*This blog is an ongoing assignment for Gov 1347: Election Analytics, a course at Harvard College taught by Professor [Ryan Enos](https://www.ryandenos.com). It will be updated weekly and culminate in a predictive model of the 2022 midterm elections.*

In this week's blog, I will be incorporating polling into my predictive modelling. I will create predictions using polling in two ways. First, I'll update a version of my economic fundamentals model from last week with polling data. Next, I'll incorporate district-level polls and partisanship indicators to forecast seat share in the 2022 midterms, completing blog extension 3.

# National Popular Vote Model
## Pure Economic Fundamentals Model
I'll begin with forecasting the popular vote. Last week, I considered a number of ways to model elections based on economic data. For this week, I'll use an economic model that predicts the popular vote of the incumbent president's party based on quarter 5 GDP growth (the GDP growth at the start of the election year). Quarter 5 growth is used since this data is available for the 2022 election cycle and can thus be used to predict the 2022 midterms. I've also included a midterm dummy variable, which has a value of 1 if it's a midterm election year and a value of 0 if it's a presidential election year. The model output is displayed below:
```{r}
## Data Wrangling

hist_polls_data <- hist_polls %>%
  filter(days_until_election < 45) %>% 
  group_by(year,party) %>% 
  summarise(avg_support = mean(support)) %>%
  spread(key = "party", value = "avg_support") %>%
  mutate(poll_margin = 100*(D-R)/(D+R))

GDP_data <- GDP %>%
  filter(quarter_cycle == 5) %>%
  select(year, GDPC1, GDP_growth_pct)

model_elec_data <- election_data %>%
  select(year, R_seats, D_seats, R_majorvote_pct, D_majorvote_pct, president_party) %>%
  mutate(incumbent_president = c("D","D","D","R","R","R","R","D","D","D","D","R","R","R","R","D","D","R","R","R","R","R", "R","D","D","D","D", "R", "R", "R","R","D","D","D","D","R","R")) %>% # Add list of incumbent presidents
  mutate(incumbent_president_dummy = ifelse(incumbent_president == "D", 1, 0)) %>% # Incumbent president dummy variable
  mutate(midterm_dummy = ifelse(year %% 4, 1, 0)) %>% # Midterm election dummy variable
  inner_join(hist_polls_data, by = "year") %>%
  mutate(incumbent_pres_majorvote = ifelse(incumbent_president == "D", D_majorvote_pct, R_majorvote_pct),
         incumbent_pres_seats = ifelse(incumbent_president == "D", D_seats, R_seats),
         incumbent_pres_polls = ifelse(incumbent_president == "D", 100*D/(R+D), 100*R/(R+D))) %>% # Assign vote/seat share for incumbent party's president to new variables
  select(year, midterm_dummy, incumbent_pres_majorvote, incumbent_pres_seats, incumbent_pres_polls, incumbent_president) %>%
  inner_join(GDP_data, by = "year")


## Model 1: Fundamentals only:
fund_model <- lm(incumbent_pres_majorvote ~ GDP_growth_pct + midterm_dummy, data = model_elec_data)
#summary(fund_model)
#tab_model(fund_model, show.se = TRUE)

## Model 2: Polls only:
poll_model <- lm(incumbent_pres_majorvote ~ incumbent_pres_polls, data = model_elec_data)
#summary(poll_model)
#tab_model(poll_model, show.se = TRUE)

## Model 3: Combined
combo_model <-lm(incumbent_pres_majorvote ~ incumbent_pres_polls + GDP_growth_pct + midterm_dummy, data = model_elec_data)
#summary(combo_model)
#tab_model(combo_model, show.se = TRUE)

## Plot Models
fig1 <- ggplot(aes(x = predict(fund_model, model_elec_data), y = incumbent_pres_majorvote, label = year), data = model_elec_data) +
  geom_text() +
  geom_abline(intercept = 0, slope = 1, color = "darkseagreen4") +
  labs(title = "Fundamentals Model") +
  xlab(label = "Predicted Incumbent President Vote Share") +
  ylab(label = "Actual Incumbent President Vote Share") +
  theme(plot.title = element_text(hjust = 0.5))

fig2 <- ggplot(aes(x = predict(poll_model, model_elec_data), y = incumbent_pres_majorvote, label = year), data = model_elec_data) +
  geom_text() +
  geom_abline(intercept = 0, slope = 1, color = "darkseagreen4") +
  labs(title = "Polls Model") +
  xlab(label = "Predicted Incumbent President Vote Share") +
  ylab(label = "Actual Incumbent President Vote Share") +
  theme(plot.title = element_text(hjust = 0.5))

fig3 <- ggplot(aes(x = predict(combo_model, model_elec_data), y = incumbent_pres_majorvote, label = year), data = model_elec_data) +
  geom_text() +
  geom_abline(intercept = 0, slope = 1, color = "darkseagreen4") +
  labs(title = "Combined Model") +
  xlab(label = "Predicted Incumbent President Vote Share") +
  ylab(label = "Actual Incumbent President Vote Share") +
  theme(plot.title = element_text(hjust = 0.5))


## Make Predictions
nat_polls$enddate <- as.Date(nat_polls$enddate, "%m/%d/%y")
nat_polls_pred <- nat_polls %>%
  filter(enddate > "2022-08-01") %>%
  mutate(dem_tp = dem/(dem + rep))

predictions_data <- NA
predictions_data$incumbent_pres_polls <- 100*mean(nat_polls_pred$dem_tp)
predictions_data$GDP_growth_pct <- GDP_data$GDP_growth_pct[GDP_data$year == 2022]
predictions_data$midterm_dummy <- 1

predict_table <- data.frame(model = "prediction", fundamentals = predict(fund_model, predictions_data), polls = predict(poll_model, predictions_data), combined = predict(combo_model, predictions_data))
```
```{r}
tab_model(fund_model, show.se = TRUE)
```
<br/>
With an R-squared value of 0.142, this is not a very good model. As we might expect, the coefficient for the midterm dummy is negative, given the [conventional](https://fivethirtyeight.com/features/why-the-presidents-party-almost-always-has-a-bad-midterm/) [wisdom](https://news.gallup.com/poll/393626/usual-midterm-indicators-unfavorable-democrats.aspx) that we generally expect the incumbent president's party to fare poorly in the midterms. But given that the p-value for the midterm variable is around 0.3, we should be highly skeptical of its predictive power. The following scatter plot shows the actual versus predicted popular vote share of the incumbent president's party in past elections based on my fundamentals-only model.
```{r}
fig1
```
<br/>
Clearly, the residuals are quite large, again suggesting that this model is not optimal. Using first quarter GDP growth from 2022, this model predicts that the incumbent president's party (the Democrats) will win around *48.42% of the two-party popular vote*. 

## Pure Polling Model
Next, I'll build a model solely based on polling data. I will predict the incumbent president's party's two-party popular vote share based on generic ballot polling. I'll determine each election year's polling average by taking an average of all polls conducted within 45 days of election day. For the sake of simplicity, I will not weight the polls based on pollster quality — FiveThirtyEight, for example, [weights](https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/) polls based on the past predictive performance of the pollster in question. I will also not weight polls based on their proximity to election day. As I continue to refine my model, I will consider different methods of weighting polls, drawing on the work of forecasters at FiveThirtyEight, The Economist, and other outlets. But for the purpose of this blog, which is focused on reconciling fundamentals- and polling-based models, I'll go with a more parsimonious approach. The output for this polling model is shown below:
```{r}
tab_model(poll_model, show.se = TRUE)
```
<br/>
Clearly, with an R-squared of around 0.701, this polling-based model is far more predictive than my previous economics-only model. A scatterplot comparing predicted and actual two-party vote share values is shown below
```{r}
fig2
```
<br/>
This model provides a much better fit of the data, with most election years falling on or near the 45 degree line. Averaging polls from the start of August to mid-September (roughly 45 days of polling) to determine the present 2022 polling average, this model predicts that that the incumbent president's party (the Democrats) will win around *49.36% of the two-party popular vote*. 

## Combined Model
Finally, I'll combine these two models to predict the popular vote based on both economic fundamentals and polling data. The multivariate regression, based on quarter 5 GDP growth, the polling average, and the midterm binary variable, is shown below.
```{r}
tab_model(combo_model, show.se = TRUE)
```
<br/>
This model does not seem much more predictive than the polls-only model. In fact, the adjusted R-squared is actually very slightly lower for the combined model than the polls-only model. This might suggest that we could remove the economic data from our model without affecting the predictiveness of the model. This is not to say that economic trends and other fundamentals do not matter at all in the midterms — it may just be that the chosen value of GDP growth is not a very useful predictor. Going forward, I'll consider how to incorporate other indicators of the baseline political environment; I may use presidential approval ratings, for example, as a means of gauging election fundamentals.

The scatterplot for the combined model is shown below:
```{r}
fig3
```
<br/>
Again, there does not seem to be much improvement in model accuracy relative to my polls-only model. Using the previously mentioned data from 2022, this combined model predicts that the incumbent president's party (the Democrats) will win around *49.09% of the two-party popular vote*. The predictions of Democratic two-party vote share for the three models are summarized below:
```{r}
tab_df(predict_table)
```
<br/>
Despite varying significantly in predictive power, all three models predict very similar popular vote shares for the Democrats. The fundamentals-only model is the most pessimistic about Democrats' chances, which aligns with the [thinking](https://news.gallup.com/poll/393626/usual-midterm-indicators-unfavorable-democrats.aspx) that the 2022 midterms are fundamentally a tough cycle for Democrats. The polls-only forecast is more optimistic about the Democrats' chances, due to [recent gains](https://projects.fivethirtyeight.com/polls/generic-ballot/) for the Democrats in generic ballot polling. And the combined model is somewhere in the middle, which makes sense given it combines the fundamentals and polling forecasts.

# District-Level Polling Model
Of course, thus far I have only considered national generic-ballot polls, not district-level polling. In this next model, I'll use district-level polling to predict seat share in the 2022 midterms. Unfortunately, polling is not available for every district-level race. Polling is expensive, and there's little need to poll non-competitive districts. Thus, we need to be able to also predict results for congressional districts that have not been polled this cycle. To deal with this, forecasters like FiveThirtyEight have used algorithms like [CANTOR](https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/), which are able to infer results in districts that have not been polled based on demographically similar districts that have been polled. For my model, I will use a simpler method to forecast the winner of districts that have little polling data available. The *Cook Political Report's* [Partisan Voter Index (PVI)](https://www.cookpolitical.com/cook-pvi/2022-partisan-voting-index/state-map-and-list) measures how Republican or Democratic a district is relative to the nation as a whole, based on presidential election data from previous cycles. For example, a district with a PVI of D+3 is around 3 points more Democratic than the nation as a whole in terms of two-party vote share. 

We can't just use PVI on its own to predict the results of congressional districts since this would presume we're in a national environment where Democratic and Republican support is equal. But we know from my previous popular vote model that the national environment currently skews Republican: based on my combined fundamentals/polling model, Democrats are only on track to win 49.09 percent of the two-party vote. In other words, relative to electoral equilibrium, Democrats trail by -0.91 percentage points in terms of the two-party vote. If we trust my national popular vote model, we can take this value to represent the national partisan environment from which congressional districts deviate. We can thus predict the two-party outcome in electoral districts by adding our value for national partisanship to the PVI of each district. This method assumes that all districts undergo uniform swing from election to election. This assumption likely fails since some demographically-similar districts may behave differently compared to other groups of demographically-similar districts. But for now we can use [uniform swing as a heuristic](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/abs/predictive-power-of-uniform-swing/571192E6749DBB5108D71D0DF7A656BC). 

Outlined below are the outputs for two district-level models. The *PVI* model simply relies on the PVI of each district, adjusted based on the current national environment. The *PVI_polls* model only uses this adjusted PVI when polling is unavailable and otherwise defers to the district-level polling.

```{r data cleaning}
district_poll_avgs <- district_polls %>%
  select(state, candidate_name, end_date, seat_number, party, pct, stage) %>%
  mutate(District = paste(state, seat_number, sep = " ")) %>%
  filter(stage == "general", state != "Alaska", party == c("REP", "DEM")) %>%
  group_by(District, party) %>%
  summarise(mean(pct)) %>%
  spread(key = "party", value = "mean(pct)")

district_poll_avgs$District[district_poll_avgs$District == "Vermont 1"] <- "Vermont at-large"

district_poll_avgs_pvi <- full_join(PVI, district_poll_avgs, by = "District")


district_poll_avgs_pvi$partymulti[grep("R", district_poll_avgs_pvi$PVI)] <- -1
district_poll_avgs_pvi$partymulti[grep("D", district_poll_avgs_pvi$PVI)] <- 1
district_poll_avgs_pvi$partymulti[grep("EVEN", district_poll_avgs_pvi$PVI)] <- 0

district_poll_avgs_pvi$PVI[district_poll_avgs_pvi$PVI == "EVEN"] <- 0
district_poll_avgs_pvi$PVI_num <- parse_number(district_poll_avgs_pvi$PVI)*district_poll_avgs_pvi$partymulti

district_poll_avgs_pvi <- district_poll_avgs_pvi %>%
  mutate(poll_lean = 50*(DEM - REP)/(DEM + REP)) %>%
  select(District, PVI_num, poll_lean, DEM, REP)

nat_polls$enddate <- as.Date(nat_polls$enddate, "%m/%d/%y")
nat_polls_margins <- nat_polls %>%
  filter(enddate > "2022-08-01") %>%
  mutate(margin = 100*(dem - rep)/(dem + rep)) %>%
  mutate(margin_adj = 100*(adjusted_dem - adjusted_rep)/(adjusted_dem + adjusted_rep))

predicted_pop_vote_margin <- predict_table$combined - 50

district_poll_avgs_pvi$diff <- district_poll_avgs_pvi$PVI_num + predicted_pop_vote_margin
district_poll_avgs_pvi$diff_poll <- ifelse(is.na(district_poll_avgs_pvi$poll_lean), district_poll_avgs_pvi$diff, ((district_poll_avgs_pvi$poll_lean)))

#sum(district_poll_avgs_pvi$diff > 0)
#sum(district_poll_avgs_pvi$diff < 0)

#sum(district_poll_avgs_pvi$diff_poll > 0)
#sum(district_poll_avgs_pvi$diff_poll < 0)
#sum(district_poll_avgs_pvi$diff_poll == 0)

seat_predict_table <- data.frame(model = c("Dem Wins", "Rep Wins", "Tied Seats", "Dem Seat Share", "Rep Seat Share"), PVI = c(sum(district_poll_avgs_pvi$diff > 0), sum(district_poll_avgs_pvi$diff < 0),0, sum(district_poll_avgs_pvi$diff > 0)/435, sum(district_poll_avgs_pvi$diff < 0)/435 ), PVI_polls = c(sum(district_poll_avgs_pvi$diff_poll > 0), sum(district_poll_avgs_pvi$diff_poll < 0), sum(district_poll_avgs_pvi$diff_poll == 0), sum(district_poll_avgs_pvi$diff_poll > 0)/435, sum(district_poll_avgs_pvi$diff_poll < 0)/435))

plot1 <- ggplot(district_poll_avgs_pvi) +
  geom_histogram(aes(x = district_poll_avgs_pvi$PVI_num), color="darkseagreen4", fill="darkseagreen3") +
  xlim(-40,40) +
  ylim(0, 38) +
  labs(title = "PVI Distribution") +
  xlab(label = "District Partisanship (+D)") +
  ylab(label = "Number of Seats") +
  theme(plot.title = element_text(hjust = 0.5))

plot2 <- ggplot(district_poll_avgs_pvi) +
  geom_histogram(aes(x = district_poll_avgs_pvi$diff_poll), color="darkseagreen4", fill="darkseagreen3") +
  xlim(-40,40) +
  ylim(0, 38) +
  labs(title = "Prediction (PVI only)") +
  xlab(label = "District Partisanship (+D)") +
  ylab(label = "Number of Seats") +
  theme(plot.title = element_text(hjust = 0.5))

plot3 <- ggplot(district_poll_avgs_pvi) +
  geom_histogram(aes(x = district_poll_avgs_pvi$diff), color="darkseagreen4", fill="darkseagreen3") +
  xlim(-40,40) +
  ylim(0, 38) +
  labs(title = "Prediction (PVI and District Polls)") +
  xlab(label = "District Partisanship (+D)") +
  ylab(label = "Number of Seats") +
  theme(plot.title = element_text(hjust = 0.5))

tab_df(seat_predict_table)
```
<br/>
Both models predict very similar seat counts for the parties, suggesting that PVI with adjustments for the national environment may be a decent stand-in for district-level polling in unpolled districts. Shown below are histograms plotting the distribution of the predicted district partisanship for the two models. (Note that a district partisanship value of 20 means we'd expect Democrats to to win roughly 50 + 20 = 70% of the two-party vote.) Plotted on the bottom is the distribution of baseline PVI for all congressional districts, without adjusting for the national environment.
```{r}
grid.arrange(plot2,plot3,plot1,ncol=2)
```
<br/>
Overall, PVI provides a helpful heuristic for modelling district-level results when district-level polls are unavailable. I'll continue to explore the value of these types of district ratings as we consider expert predictions next week.
